# Evaluation & Qualitäts‑Checks (praxisnah)

Kurzer Nutzen: Lerne, wie du die Qualität deiner KI‑Ergebnisse mit einfachen Heuristiken misst, dokumentierst und Regressionen früh erkennst.

Video ansehen: https://video.bunny.net/TODO-eval-monitor

## Warum das wichtig ist

Ohne Messung keine Verbesserung. Ein leichtgewichtiges Eval‑Set (10–20 Fälle) deckt viele Fehler früh auf und spart Kosten. Du brauchst keine komplexen Pipelines: Starte mit Pass/Fail‑Heuristiken und erweitere iterativ.

<Tip>
  Lege ein kleines, repräsentatives Eval‑Set an (Golden Prompts) und nutze es
  regelmäßig nach Änderungen.
</Tip>

## So gehst du vor

1. Sammle 10–20 typische Eingaben (Golden Prompts) mit erwarteten Outcomes.
2. Implementiere 2–3 Heuristiken (z. B. enthält Schlüsselwörter, JSON ist valide, Zeichenlänge ≤ X).
3. Führe die Heuristiken über alle Fälle, zähle Pass/Fail und notiere Kosten/Token.
4. Dokumentiere Änderungen (Changelog) und vergleiche Scores über die Zeit.

```ts
// Kleiner Eval‑Runner über N Fällen
type Case = { input: string; expected?: string };

const cases: Case[] = [
  { input: "Produktbeschreibung für XYZ" },
  { input: "Fasse Artikel ABC in 3 Sätzen zusammen" },
];

function heuristic(output: string) {
  // Beispiel: minimaler Format‑Check
  return output.length > 10 && output.length < 2000;
}

export async function runEval(call: (input: string) => Promise<string>) {
  let pass = 0;
  for (const c of cases) {
    const out = await call(c.input);
    if (heuristic(out)) pass += 1;
  }
  const score = pass / cases.length;
  return { pass, total: cases.length, score };
}
```

<Warning>
  Overfitting vermeiden: Optimiere nicht stur auf dein Eval‑Set. Ergänze es
  gelegentlich um neue Fälle.
</Warning>

## Mini‑Aufgabe

Lege ein kleines Eval‑Set an und implementiere 2 Heuristiken. Führe den Eval‑Runner gegen deine aktuelle Prompt‑Version aus.

<Checklist
  id="lesson-06-tasks"
  items={[
    { id: "t1", label: "Eval‑Set erstellt (10–20 Fälle)" },
    { id: "t2", label: "Heuristiken definiert" },
    { id: "t3", label: "Eval ausgeführt & Score notiert" },
  ]}
/>

Weiterführende Ressourcen:

- Einfache LLM‑Eval‑Ideen – TODO Link
- Prompt‑Regressionen erkennen – TODO Link
